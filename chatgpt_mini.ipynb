{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "lPZDZzbeLJa9"
      },
      "outputs": [],
      "source": [
        "#!wget https://raw.githubusercontent.com/karpathy/char_rnn/master/tiny/shakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt','r',encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "KXVGPBcERz1D"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 자연어 간단 처리과정\n",
        "# content minibatch size로 토큰화 -> 임베딩 벡터로 임베딩 -> neural net -> backprop"
      ],
      "metadata": {
        "id": "6rpKSNi-ehUC"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)\n",
        "# text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6JeRRySsQ-",
        "outputId": "7f1a379f-e3d4-4f70-f761-f376402ee3db"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars)) # 셰익스피어 txt 모든 문자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ6NkGhHS2PN",
        "outputId": "0fe0a0b2-7b61-495b-9a51-0d4057d3863b"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s : [stoi[c] for c in s]\n",
        "# s = string c = char 문자열마다 숫자로 바꿈\n",
        "# decode = lambda i : [itos[n] for n in i]\n",
        "# decode= lambda l : ''.join([itos[n] for n in l])\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode('hello world')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so3IpRZETbAl",
        "outputId": "1d5d3102-804a-43e2-bf60-26b679dc710e"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdpkbA1Ie8wV",
        "outputId": "c14a2ad0-3868-4d56-be4d-5e23ae1567c2"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text),dtype = torch.long) #매우간단한 수동 인코딩\n",
        "# openai chatgpt 는 tiktoken 이란 bpe tokenizer 인코딩 방식사용\n",
        "# google 은 sentencepiece라는 걸사용\n",
        "data.type\n",
        "print(data.shape)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X7h8lVdV1pg",
        "outputId": "01ca26db-27fa-40bf-ef07-15a23cf93125"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394])\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(len(text)*0.9)\n",
        "train = data[:n]\n",
        "val = data[n:]\n",
        "blocksize = 8 #WAVENET\n",
        "train[:blocksize+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUbAKWr-Wj9v",
        "outputId": "eb3d748f-4c2f-48e7-a0c2-b0601f4f4ee6"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train[:blocksize]\n",
        "y= train[1:blocksize+1]\n",
        "for t in range(blocksize):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "\n",
        "# x=target string 전까지의 모든 string의 tokenized 된int, y= target\n",
        "\n",
        "\n",
        "  print(f'입력값이 {context} 일 때 입력값 sequence의 다음값은 {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lnlt9I3W2tB",
        "outputId": "c515eaa4-4e35-4df5-e595-69d33baced42"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력값이 tensor([18]) 일 때 입력값 sequence의 다음값은 47\n",
            "입력값이 tensor([18, 47]) 일 때 입력값 sequence의 다음값은 56\n",
            "입력값이 tensor([18, 47, 56]) 일 때 입력값 sequence의 다음값은 57\n",
            "입력값이 tensor([18, 47, 56, 57]) 일 때 입력값 sequence의 다음값은 58\n",
            "입력값이 tensor([18, 47, 56, 57, 58]) 일 때 입력값 sequence의 다음값은 1\n",
            "입력값이 tensor([18, 47, 56, 57, 58,  1]) 일 때 입력값 sequence의 다음값은 15\n",
            "입력값이 tensor([18, 47, 56, 57, 58,  1, 15]) 일 때 입력값 sequence의 다음값은 47\n",
            "입력값이 tensor([18, 47, 56, 57, 58,  1, 15, 47]) 일 때 입력값 sequence의 다음값은 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "batchsize = 4 #병렬처리\n",
        "blocksize = 8 #예측에 사용되는 최대 context길이\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train if split == 'train' else val\n",
        "  ix =torch.randint(len(data)-blocksize,(batchsize,)) #0~len(data)-blocksize에서 랜덤한 정수\n",
        "  # 총 데이터에서 4개씩 idx설정\n",
        "  x = torch.stack([data[i:i+blocksize] for i in ix])  #chunking\n",
        "  # 위의 짧은 snippet과 동일한과정 but 전체 data에 for문을 처리해 적용\n",
        "  y = torch.stack([data[i+1:i+blocksize+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "  # ix shape (4,) data shape (1115394) data[ix:ix+blocksize] shape (4,8)\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print(xb,xb.shape)\n",
        "print('-------------------------------------------------')\n",
        "print(yb.shape,yb)\n",
        "for b in range(batchsize):  #batch dimension\n",
        "  for t in range(blocksize):  #time dimension  e.g wavenet B,T,C\n",
        "    context  = xb[b,:t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'입력값이 {context.tolist()} 일때 입력값 sequence 다음값은 {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4St5oOQtsXC5",
        "outputId": "79f7f532-0155-4cdb-e707-c926b7301a5d"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]]) torch.Size([4, 8])\n",
            "-------------------------------------------------\n",
            "torch.Size([4, 8]) tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "입력값이 [24] 일때 입력값 sequence 다음값은 43\n",
            "입력값이 [24, 43] 일때 입력값 sequence 다음값은 58\n",
            "입력값이 [24, 43, 58] 일때 입력값 sequence 다음값은 5\n",
            "입력값이 [24, 43, 58, 5] 일때 입력값 sequence 다음값은 57\n",
            "입력값이 [24, 43, 58, 5, 57] 일때 입력값 sequence 다음값은 1\n",
            "입력값이 [24, 43, 58, 5, 57, 1] 일때 입력값 sequence 다음값은 46\n",
            "입력값이 [24, 43, 58, 5, 57, 1, 46] 일때 입력값 sequence 다음값은 43\n",
            "입력값이 [24, 43, 58, 5, 57, 1, 46, 43] 일때 입력값 sequence 다음값은 39\n",
            "입력값이 [44] 일때 입력값 sequence 다음값은 53\n",
            "입력값이 [44, 53] 일때 입력값 sequence 다음값은 56\n",
            "입력값이 [44, 53, 56] 일때 입력값 sequence 다음값은 1\n",
            "입력값이 [44, 53, 56, 1] 일때 입력값 sequence 다음값은 58\n",
            "입력값이 [44, 53, 56, 1, 58] 일때 입력값 sequence 다음값은 46\n",
            "입력값이 [44, 53, 56, 1, 58, 46] 일때 입력값 sequence 다음값은 39\n",
            "입력값이 [44, 53, 56, 1, 58, 46, 39] 일때 입력값 sequence 다음값은 58\n",
            "입력값이 [44, 53, 56, 1, 58, 46, 39, 58] 일때 입력값 sequence 다음값은 1\n",
            "입력값이 [52] 일때 입력값 sequence 다음값은 58\n",
            "입력값이 [52, 58] 일때 입력값 sequence 다음값은 1\n",
            "입력값이 [52, 58, 1] 일때 입력값 sequence 다음값은 58\n",
            "입력값이 [52, 58, 1, 58] 일때 입력값 sequence 다음값은 46\n",
            "입력값이 [52, 58, 1, 58, 46] 일때 입력값 sequence 다음값은 39\n",
            "입력값이 [52, 58, 1, 58, 46, 39] 일때 입력값 sequence 다음값은 58\n",
            "입력값이 [52, 58, 1, 58, 46, 39, 58] 일때 입력값 sequence 다음값은 1\n",
            "입력값이 [52, 58, 1, 58, 46, 39, 58, 1] 일때 입력값 sequence 다음값은 46\n",
            "입력값이 [25] 일때 입력값 sequence 다음값은 17\n",
            "입력값이 [25, 17] 일때 입력값 sequence 다음값은 27\n",
            "입력값이 [25, 17, 27] 일때 입력값 sequence 다음값은 10\n",
            "입력값이 [25, 17, 27, 10] 일때 입력값 sequence 다음값은 0\n",
            "입력값이 [25, 17, 27, 10, 0] 일때 입력값 sequence 다음값은 21\n",
            "입력값이 [25, 17, 27, 10, 0, 21] 일때 입력값 sequence 다음값은 1\n",
            "입력값이 [25, 17, 27, 10, 0, 21, 1] 일때 입력값 sequence 다음값은 54\n",
            "입력값이 [25, 17, 27, 10, 0, 21, 1, 54] 일때 입력값 sequence 다음값은 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "FK6nzI7Y0SoN"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "class blm(nn.Module): #bigram language model\n",
        "  def __init__(self,vocab_size):\n",
        "      super().__init__()\n",
        "      self.token_emb_table = nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "  def forward(self,idx, targets=None):\n",
        "      # idx,xb =4,8 idx의미 embedding matrix의 idx = 단어정보의 int를 batchsize로 묶은 벡터\n",
        "      # idx,targets 모두 B,T shape tensor\n",
        "      logits = self.token_emb_table(idx)  #C[xb]와 유사 wavenet\n",
        "\n",
        "      if targets is None:\n",
        "        loss = None\n",
        "      else:\n",
        "        B,T,C = logits.shape\n",
        "        logits = logits.view(B*T,C) #logits shpae =B,T,C #벡터값으로 reshape\n",
        "        targets = targets.view(B*T) #스칼라값\n",
        "        loss = F.cross_entropy(logits,targets)\n",
        "\n",
        "      return logits,loss\n",
        "\n",
        "\n",
        "\n",
        "# 이전에 생성된 토큰들에 대한 정보를 유지하면서 새로운 토큰을 생성함.\n",
        "# 이는 텍스트 생성과 같은 작업에서 이전 문맥을 유지하면서 연속된 문장이나\n",
        "# 시퀀스를 생성하는 데 사용됨. 밑의 idx generate과정이 이에 해당함\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    #idx shape = B,T\n",
        "      for _ in range(max_new_tokens):\n",
        "        #예측값을 얻음 loss는 계산되지않음\n",
        "        # 위의 target이 optional 이기 때문에 argument idx 한개여도 forward 실행가능\n",
        "        # self 를 instance로\n",
        "        logits, loss = self(idx)\n",
        "        logits = logits[:,-1,:] #embedding된 토큰에서의 timestep의 마지막 토큰\n",
        "        probs = F.softmax(logits,dim=-1)\n",
        "        idx_next = torch.multinomial(probs,num_samples=1)\n",
        "        idx = torch.cat((idx,idx_next),dim=1)\n",
        "      return idx\n",
        "\n",
        "m= blm(vocab_size)\n",
        "logits,loss = m(xb,yb) #forward pass 인스턴스를 함수로써 __call__과 유사\n",
        "print(logits.shape) #65 = vocab size\n",
        "print(loss)\n",
        "# -ln(1/65)와 loss값이 다름으로 prediciton 잘못된 generate로 idx형성\n",
        "# idx = torch.zeros((1,1),dtype= torch.long)\n",
        "print(decode(m.generate(idx = torch.zeros((1,1),dtype= torch.long),max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdB6xOFY_XTv",
        "outputId": "d433581d-4d19-40e0-fd22-038bf385dc2a"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forward pass done\n",
        "#훈련 ㄱ\n",
        "optimizer = torch.optim.AdamW(m.parameters(),lr = 1e-3)\n",
        "batchsize =32\n",
        "for steps in range(10000):\n",
        "  # xb = idx, yb = targets\n",
        "  xb,yb = get_batch('train')\n",
        "\n",
        "  logits,loss = m(xb,yb)\n",
        "  # 항상하는 gradient 초기값설정 과정\n",
        "  # for p in parameters: p.grad =None parameters = [p for layer in layers for p in layer.parameter()]\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAaCFNZ9D52m",
        "outputId": "1a67ee3e-6cfa-436d-bbc8-364f247368ac"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.498678684234619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o80jiTEiBA_K",
        "outputId": "aca68de0-4864-4648-94fd-f5c8c0a13225"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2\n",
        "x= torch.randn(B,T,C)\n",
        "x.shape\n",
        "xbow = torch.zeros((B,T,C)) #x의 평균 저장할 공간\n",
        "# bow = bag of words 평균낼때 사용\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    # xprev shape (t,C)\n",
        "    # batch dimentsion는 정해진값, t를 포함한 t까지의 time token까지 slicing\n",
        "    xprev = x[b,:t+1]\n",
        "    # torch.mean(xprev,0) shape 는 xprev의 0:t에서의 평균을 구함\n",
        "    xbow[b,t] = torch.mean(xprev,0) #row에서 xprev[0]에서 mean\n",
        "\n",
        "# 밑의 x표, xprev 는 x=[[ 0.1808, -0.0700],[-0.3596, -0.9152],...]에서\n",
        "  # t가0일때는 # [ 0.1808, -0.0700] 0.1808 의평균\n",
        "  # t가1일떄는 [ 0.1808, -0.0700],[-0.3596, -0.9152]의 row값에서의 평균\n",
        "  # t가 2일떄 0.1808 -0.3596 0.6258 평균 row에서의 평균\n",
        "  #이값을 xbow에 채워 넣음\n",
        "\n",
        "#       ([[[ 0.1808, -0.0700],\n",
        "        #  [-0.3596, -0.9152],\n",
        "        #  [ 0.6258,  0.0255],\n",
        "        #  [ 0.9545,  0.0643],\n",
        "        #  [ 0.3612,  1.1679],\n",
        "        #  [-1.3499, -0.5102],\n",
        "        #  [ 0.2360, -0.2398],\n",
        "        #  [-0.9211,  1.5433]],\n",
        "\n",
        "        # [[ 1.3488, -0.1396],\n",
        "        #  [ 0.2858,  0.9651],\n",
        "        #  [-2.0371,  0.4931],\n",
        "        #  [ 1.4870,  0.5910],\n",
        "        #  [ 0.1260, -1.5627],\n",
        "        #  [-1.1601, -0.3348],\n",
        "        #  [ 0.4478, -0.8016],\n",
        "        #  [ 1.5236,  2.5086]],\n",
        "print(x,xbow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZvzYQfOv6iq",
        "outputId": "a3734363-726c-4e30-89e6-97e199ea50a8"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.2858,  0.9651],\n",
            "         [-2.0371,  0.4931],\n",
            "         [ 1.4870,  0.5910],\n",
            "         [ 0.1260, -1.5627],\n",
            "         [-1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016],\n",
            "         [ 1.5236,  2.5086]],\n",
            "\n",
            "        [[-0.6631, -0.2513],\n",
            "         [ 1.0101,  0.1215],\n",
            "         [ 0.1584,  1.1340],\n",
            "         [-1.1539, -0.2984],\n",
            "         [-0.5075, -0.9239],\n",
            "         [ 0.5467, -1.4948],\n",
            "         [-1.2057,  0.5718],\n",
            "         [-0.5974, -0.6937]],\n",
            "\n",
            "        [[ 1.6455, -0.8030],\n",
            "         [ 1.3514, -0.2759],\n",
            "         [-1.5108,  2.1048],\n",
            "         [ 2.7630, -1.7465],\n",
            "         [ 1.4516, -1.5103],\n",
            "         [ 0.8212, -0.2115],\n",
            "         [ 0.7789,  1.5333],\n",
            "         [ 1.6097, -0.4032]]]) tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.0894, -0.4926],\n",
            "         [ 0.1490, -0.3199],\n",
            "         [ 0.3504, -0.2238],\n",
            "         [ 0.3525,  0.0545],\n",
            "         [ 0.0688, -0.0396],\n",
            "         [ 0.0927, -0.0682],\n",
            "         [-0.0341,  0.1332]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.8173,  0.4127],\n",
            "         [-0.1342,  0.4395],\n",
            "         [ 0.2711,  0.4774],\n",
            "         [ 0.2421,  0.0694],\n",
            "         [ 0.0084,  0.0020],\n",
            "         [ 0.0712, -0.1128],\n",
            "         [ 0.2527,  0.2149]],\n",
            "\n",
            "        [[-0.6631, -0.2513],\n",
            "         [ 0.1735, -0.0649],\n",
            "         [ 0.1685,  0.3348],\n",
            "         [-0.1621,  0.1765],\n",
            "         [-0.2312, -0.0436],\n",
            "         [-0.1015, -0.2855],\n",
            "         [-0.2593, -0.1630],\n",
            "         [-0.3015, -0.2293]],\n",
            "\n",
            "        [[ 1.6455, -0.8030],\n",
            "         [ 1.4985, -0.5395],\n",
            "         [ 0.4954,  0.3420],\n",
            "         [ 1.0623, -0.1802],\n",
            "         [ 1.1401, -0.4462],\n",
            "         [ 1.0870, -0.4071],\n",
            "         [ 1.0430, -0.1299],\n",
            "         [ 1.1138, -0.1641]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 매우 복잡함으로 mathmetical trick comes in\n"
      ],
      "metadata": {
        "id": "HRJnb4B30pxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbiayBcL0hRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#"
      ],
      "metadata": {
        "id": "m1W_0AImy_mT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}